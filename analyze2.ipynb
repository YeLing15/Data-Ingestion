{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x1fa0dbbaf50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Vietnamese NLP model\n",
    "nlp = spacy.blank(\"vi\")\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                            phenikaa\n",
       " 0                             Đại học,Tin tuyển sinh\n",
       " 1        Đại học (https://tuyensinh.edu.vn/dai-hoc/)\n",
       " 2  Tin tuyển sinh (https://tuyensinh.edu.vn/tin-t...\n",
       " 3  Trường Đại học Phenikaa công bố 5 phương thức ...\n",
       " 4  Trường Đại học Phenikaa công bố thông tin tuyể...,\n",
       "                                          tonducthang\n",
       " 0                             Đại học,Tin tuyển sinh\n",
       " 1        Đại học (https://tuyensinh.edu.vn/dai-hoc/)\n",
       " 2  Tin tuyển sinh (https://tuyensinh.edu.vn/tin-t...\n",
       " 3  Trường ĐH Tôn Đức Thắng chỉ dành 25% chỉ tiêu ...\n",
       " 4  Theo phương án tuyển sinh dự kiến, năm 2022 Tr...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Đọc file\n",
    "file_path1 = \"crawled/data_tuyen_sinh_phenikaa.txt\"\n",
    "file_path2 = \"crawled/data_tuyen_sinh_ton_duc_thang.txt\"\n",
    "\n",
    "with open(file_path1, \"r\", encoding=\"utf-8\") as file1:\n",
    "    data1 = file1.read().strip().split(\"\\n\")\n",
    "\n",
    "with open(file_path2, \"r\", encoding=\"utf-8\") as file2:\n",
    "    data2 = file2.read().strip().split(\"\\n\")\n",
    "\n",
    "# Tạo DataFrame\n",
    "df_phenikaa = pd.DataFrame(data1, columns=[\"phenikaa\"])\n",
    "df_tonducthang = pd.DataFrame(data2, columns=[\"tonducthang\"])\n",
    "\n",
    "# Kiểm tra dữ liệu\n",
    "df_phenikaa.head(), df_tonducthang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                            phenikaa\n",
       " 0                              Đại họcTin tuyển sinh\n",
       " 1                Đại học httpstuyensinh.edu.vndaihoc\n",
       " 2   Tin tuyển sinh httpstuyensinh.edu.vntintuyensinh\n",
       " 3  Trường Đại học Phenikaa công bố 5 phương thức ...\n",
       " 4  Trường Đại học Phenikaa công bố thông tin tuyể...,\n",
       "                                          tonducthang\n",
       " 0                              Đại họcTin tuyển sinh\n",
       " 1                Đại học httpstuyensinh.edu.vndaihoc\n",
       " 2   Tin tuyển sinh httpstuyensinh.edu.vntintuyensinh\n",
       " 3  Trường ĐH Tôn Đức Thắng chỉ dành 25 chỉ tiêu x...\n",
       " 4  Theo phương án tuyển sinh dự kiến năm 2022 Trư...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Xóa dấu câu (trừ . ! ?), giữ chữ thường\"\"\"\n",
    "    text = re.sub(r\"[^\\w\\s.!?]\", \"\", text)  # Giữ lại dấu chấm, chấm than, chấm hỏi\n",
    "    return text.strip()\n",
    "\n",
    "df_phenikaa[\"phenikaa\"] = df_phenikaa[\"phenikaa\"].apply(clean_text)\n",
    "df_tonducthang[\"tonducthang\"] = df_tonducthang[\"tonducthang\"].apply(clean_text)\n",
    "\n",
    "# Kiểm tra dữ liệu sau làm sạch\n",
    "df_phenikaa.head(), df_tonducthang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Total Words': 816, 'Total Sentences': 153, 'Total Paragraphs': 79},\n",
       " {'Total Words': 285, 'Total Sentences': 57, 'Total Paragraphs': 27})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_sentences(text):\n",
    "    \"\"\"Chia văn bản thành câu dựa trên dấu câu bằng spaCy\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "def count_words(text):\n",
    "    \"\"\"Đếm số từ bằng spaCy\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return len([token for token in doc if token.is_alpha])\n",
    "\n",
    "def count_stats(texts):\n",
    "    \"\"\"Đếm tổng số từ, câu và đoạn văn \"\"\"\n",
    "    total_words = sum(count_words(text) for text in texts)\n",
    "    total_sentences = sum(len(split_sentences(text)) for text in texts)\n",
    "    total_paragraphs = sum(len(text.strip().split(\"\\n\")) for text in texts)\n",
    "\n",
    "    return {\n",
    "        \"Total Words\": total_words,\n",
    "        \"Total Sentences\": total_sentences,\n",
    "        \"Total Paragraphs\": total_paragraphs\n",
    "    }\n",
    "\n",
    "# Thống kê cho từng tài liệu\n",
    "stats_phenikaa = count_stats(df_phenikaa[\"phenikaa\"])\n",
    "stats_tonducthang = count_stats(df_tonducthang[\"tonducthang\"])\n",
    "\n",
    "stats_phenikaa, stats_tonducthang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('tuyển', 62),\n",
       "  ('học', 61),\n",
       "  ('xét', 48),\n",
       "  ('sinh', 40),\n",
       "  ('các', 28),\n",
       "  ('có', 23),\n",
       "  ('điểm', 23),\n",
       "  ('với', 22),\n",
       "  ('từ', 21),\n",
       "  ('Trường', 20)],\n",
       " [('tuyển', 21),\n",
       "  ('học', 19),\n",
       "  ('xét', 18),\n",
       "  ('chỉ', 16),\n",
       "  ('sinh', 14),\n",
       "  ('ĐH', 13),\n",
       "  ('trình', 12),\n",
       "  ('THPT', 11),\n",
       "  ('chương', 11),\n",
       "  ('kết', 11)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_word_frequency(texts):\n",
    "    \"\"\"Tạo danh sách từ vựng ban đầu và tính tần suất\"\"\"\n",
    "    vocab = Counter()\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        vocab.update(words)\n",
    "    return vocab\n",
    "\n",
    "# Tính từ vựng ban đầu\n",
    "vocab_phenikaa = compute_word_frequency(df_phenikaa[\"phenikaa\"])\n",
    "vocab_tonducthang = compute_word_frequency(df_tonducthang[\"tonducthang\"])\n",
    "\n",
    "# Hiển thị 10 từ phổ biến nhất\n",
    "vocab_phenikaa.most_common(10), vocab_tonducthang.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('tuyển', 62),\n",
       "  ('học', 61),\n",
       "  ('xét', 48),\n",
       "  ('sinh', 40),\n",
       "  ('Trường', 20),\n",
       "  ('hợp', 20),\n",
       "  ('Đại', 18),\n",
       "  ('thí', 17),\n",
       "  ('môn', 15),\n",
       "  ('trở', 15)],\n",
       " [('tuyển', 21),\n",
       "  ('học', 19),\n",
       "  ('xét', 18),\n",
       "  ('sinh', 14),\n",
       "  ('ĐH', 13),\n",
       "  ('trình', 12),\n",
       "  ('THPT', 11),\n",
       "  ('chương', 11),\n",
       "  ('kết', 11),\n",
       "  ('Trường', 10)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS_FILE = \"vietnamese-stopwords.txt\"\n",
    "VIETNAMESE_STOPWORDS = set()\n",
    "\n",
    "if os.path.exists(STOPWORDS_FILE):\n",
    "    with open(STOPWORDS_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "        VIETNAMESE_STOPWORDS = set(file.read().strip().split(\"\\n\"))\n",
    "\n",
    "def remove_stopwords(vocab):\n",
    "    \"\"\"Loại bỏ stopwords khỏi từ vựng\"\"\"\n",
    "    return {word: freq for word, freq in vocab.items() if word not in VIETNAMESE_STOPWORDS}\n",
    "\n",
    "# Tạo từ vựng mới sau khi loại bỏ stopwords\n",
    "vocab_v2_phenikaa = remove_stopwords(vocab_phenikaa)\n",
    "vocab_v2_tonducthang = remove_stopwords(vocab_tonducthang)\n",
    "\n",
    "# Hiển thị 10 từ phổ biến nhất sau khi loại bỏ stopwords\n",
    "sorted(vocab_v2_phenikaa.items(), key=lambda x: x[1], reverse=True)[:10], sorted(vocab_v2_tonducthang.items(), key=lambda x: x[1], reverse=True)[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1816, 1737, 1662, 605, 578, 554)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_ngrams(texts):\n",
    "    \"\"\"Trích xuất unigrams, bigrams và trigrams\"\"\"\n",
    "    unigrams, bigrams, trigrams = [], [], []\n",
    "    \n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        unigrams.extend(words)\n",
    "        bigrams.extend(zip(words[:-1], words[1:]))\n",
    "        trigrams.extend(zip(words[:-2], words[1:-1], words[2:]))\n",
    "\n",
    "    return unigrams, bigrams, trigrams\n",
    "\n",
    "# Trích xuất n-grams\n",
    "unigrams_p, bigrams_p, trigrams_p = extract_ngrams(df_phenikaa[\"phenikaa\"])\n",
    "unigrams_t, bigrams_t, trigrams_t = extract_ngrams(df_tonducthang[\"tonducthang\"])\n",
    "\n",
    "# Hiển thị kết quả\n",
    "len(unigrams_p), len(bigrams_p), len(trigrams_p), len(unigrams_t), len(bigrams_t), len(trigrams_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phenikaa: 0     []\n",
      "1     []\n",
      "2     []\n",
      "3     []\n",
      "4     []\n",
      "      ..\n",
      "74    []\n",
      "75    []\n",
      "76    []\n",
      "77    []\n",
      "78    []\n",
      "Name: phenikaa, Length: 79, dtype: object\n",
      "Ton Duc Thang: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linh.nguyenkhanh3\\AppData\\Local\\Temp\\ipykernel_7112\\1058200553.py:20: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  df_phenikaa[\"phenikaa\"] = df_phenikaa[\"phenikaa\"].apply(lambda x: extract_anchor_texts([x]) if pd.notna(x) else [])\n"
     ]
    }
   ],
   "source": [
    "def extract_anchor_texts(texts):\n",
    "    \"\"\"Trích xuất anchor text từ danh sách văn bản có dạng text (link)\"\"\"\n",
    "    anchor_texts = []\n",
    "    \n",
    "    # Regex tìm text có dạng \"text (URL)\"\n",
    "    pattern = r\"(\\S.*?)(?:\\s*)\\((https?://[^\\s)]+)\\)\"\n",
    "\n",
    "    # Chuyển đổi pandas.Series thành danh sách chuỗi\n",
    "    if isinstance(texts, pd.Series):\n",
    "        texts = texts.dropna().astype(str).tolist()\n",
    "\n",
    "    # Duyệt từng chuỗi trong danh sách\n",
    "    for text in texts:\n",
    "        matches = re.findall(pattern, text)\n",
    "        anchor_texts.extend([match[0].strip() for match in matches])\n",
    "\n",
    "    return anchor_texts\n",
    "\n",
    "# Trích xuất anchor text\n",
    "df_phenikaa[\"phenikaa\"] = df_phenikaa[\"phenikaa\"].apply(lambda x: extract_anchor_texts([x]) if pd.notna(x) else [])\n",
    "anchors_t = extract_anchor_texts(df_tonducthang[\"tonducthang\"])\n",
    "\n",
    "print(\"Phenikaa:\", df_phenikaa[\"phenikaa\"])\n",
    "print(\"Ton Duc Thang:\", anchors_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_named_entities(texts):\n",
    "    \"\"\"Thực hiện Named Entity Recognition (NER)\"\"\"\n",
    "    entities = []\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        for ent in doc.ents:\n",
    "            entities.append((ent.text, ent.label_))\n",
    "    return entities\n",
    "\n",
    "# Thực hiện NER\n",
    "ner_phenikaa = extract_named_entities(df_phenikaa[\"phenikaa\"])\n",
    "ner_tonducthang = extract_named_entities(df_tonducthang[\"tonducthang\"])\n",
    "\n",
    "ner_phenikaa[:10], ner_tonducthang[:10]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
