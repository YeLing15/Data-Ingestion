{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save_stats(url, div_id=None, div_class=None, section_class=None):\n",
    "    driver = webdriver.Chrome()\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        \n",
    "        if div_id:\n",
    "            wait.until(EC.presence_of_element_located((By.ID, div_id)))\n",
    "        elif div_class:\n",
    "            wait.until(EC.presence_of_element_located((By.CLASS_NAME, div_class)))\n",
    "        elif section_class:\n",
    "            wait.until(EC.presence_of_element_located((By.CLASS_NAME, section_class)))\n",
    "        \n",
    "        page_source = driver.page_source\n",
    "        soup = bs(page_source, 'html.parser')\n",
    "\n",
    "        target_element = None\n",
    "        if div_id:\n",
    "            target_element = soup.find('div', {'id': div_id})\n",
    "        elif div_class:\n",
    "            target_element = soup.find('div', {'class': div_class})\n",
    "        elif section_class:\n",
    "            target_element = soup.find('section', {'class': section_class})\n",
    "        else:\n",
    "            target_element = soup.body  # Nếu không có thông số, lấy toàn bộ trang\n",
    "\n",
    "        if not target_element:\n",
    "            print(\"Error: Element with specified identifier not found.\")\n",
    "            return None\n",
    "\n",
    "        content = []\n",
    "        for elem in target_element.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'a']):\n",
    "            text = elem.get_text(strip=True)\n",
    "            if elem.name == 'a' and elem.has_attr('href'):\n",
    "                text += f\" ({elem['href']})\"\n",
    "            if text:\n",
    "                content.append([text])\n",
    "\n",
    "        df = pd.DataFrame(content, columns=[\"Text\"])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_multiple_stats(urls):\n",
    "    dataframes = {}\n",
    "    for key, info in urls.items():\n",
    "        df = fetch_and_save_stats(info[\"url\"], div_id=info.get(\"div_id\"), div_class=info.get(\"div_class\"), section_class=info.get(\"section_class\"))\n",
    "        if df is not None:\n",
    "            dataframes[key] = df\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    \"tuyen_sinh_ton_duc_thang\": {\n",
    "        \"url\": \"https://tuyensinh.edu.vn/dai-hoc/truong-dh-ton-duc-thang-chi-danh-25-chi-tieu-xet-diem-thi-tot-nghiep-thpt/\",\n",
    "        \"div_id\": \"content\",\n",
    "        \"div_class\": \"entry-content single-page\",\n",
    "    },\n",
    "    \"tuyen_sinh_phenikaa\": {\n",
    "        \"url\": \"https://tuyensinh.edu.vn/tin-tuyen-sinh/truong-dai-hoc-phenikaa-cong-bo-5-phuong-thuc-tuyen-sinh-dai-hoc-nam-2022/\",\n",
    "        \"div_id\": \"content\",\n",
    "        \"div_class\": \"entry-content single-page\",\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame for tuyen_sinh_ton_duc_thang:\n",
      "                                                 Text\n",
      "0                              Đại học,Tin tuyển sinh\n",
      "1         Đại học (https://tuyensinh.edu.vn/dai-hoc/)\n",
      "2   Tin tuyển sinh (https://tuyensinh.edu.vn/tin-t...\n",
      "3   Trường ĐH Tôn Đức Thắng chỉ dành 25% chỉ tiêu ...\n",
      "4   Theo phương án tuyển sinh dự kiến, năm 2022 Tr...\n",
      "5   Hôm nay 19.1, Trường ĐH Tôn Đức Thắng công bố ...\n",
      "6   Trường ĐH Tôn Đức Thắng dự kiến tuyển 6.500 ch...\n",
      "7   Trường dự kiến tuyển theo 5 phương thức, trong...\n",
      "8   Phương thức 1là xét tuyển theo kết quả quá trì...\n",
      "9   Trong đó, đợt 1 xét tuyển theo kết quả học tập...\n",
      "10  Đợt 2 xét tuyển theo kết quả học tập 6 học kỳ ...\n",
      "11  Đợt 3 xét tuyển theo kết quả học tập 6 học kỳ ...\n",
      "12  Phương thức 2là xét tuyển theo kết quả thi tốt...\n",
      "13  Phương thức 3là ưu tiên xét tuyển theo quy địn...\n",
      "14  Trong đó, đối tượng 1 là thí sinh thuộc các tr...\n",
      "15  Đối tượng 2, 3, 4, 5 xét tuyển vào chương trìn...\n",
      "16  Phương thức 4là xét tuyển thẳng, ưu tiên xét t...\n",
      "17  Phương thức 5là xét tuyển theo kết quả bài thi...\n",
      "18  Thông tin ngành đào tạo, tổ hợp môn xét tuyển ...\n",
      "19  tại đây (https://tuyensinh.edu.vn/wp-content/u...\n",
      "20  Như vậy, so với năm 2021 Trường ĐH Tôn Đức Thắ...\n",
      "21   (whatsapp://send?text=Tr%C6%B0%E1%BB%9Dng%20%...\n",
      "22   (//www.facebook.com/sharer.php?u=https://tuye...\n",
      "23   (//twitter.com/share?url=https://tuyensinh.ed...\n",
      "24   (//tumblr.com/widgets/share/tool?canonicalUrl...\n",
      "25  Tuyển sinh 2022: Nhóm ngành ‘nóng’ có nhiều bi...\n",
      "26  Năm 2022, ĐH Quốc gia TP.HCM tổ chức 2 đợt thi...\n",
      "\n",
      "DataFrame for tuyen_sinh_phenikaa:\n",
      "                                                 Text\n",
      "0                              Đại học,Tin tuyển sinh\n",
      "1         Đại học (https://tuyensinh.edu.vn/dai-hoc/)\n",
      "2   Tin tuyển sinh (https://tuyensinh.edu.vn/tin-t...\n",
      "3   Trường Đại học Phenikaa công bố 5 phương thức ...\n",
      "4   Trường Đại học Phenikaa công bố thông tin tuyể...\n",
      "..                                                ...\n",
      "74   (//www.facebook.com/sharer.php?u=https://tuye...\n",
      "75   (//twitter.com/share?url=https://tuyensinh.ed...\n",
      "76   (//tumblr.com/widgets/share/tool?canonicalUrl...\n",
      "77  Điểm chuẩn Đại Học Giáo Dục – Đại học Quốc Gia...\n",
      "78  ĐH Công nghiệp Hà Nội thêm 3 phương thức xét t...\n",
      "\n",
      "[79 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "dataframes = fetch_multiple_stats(urls)\n",
    "\n",
    "for key, df in dataframes.items():\n",
    "    print(f\"\\nDataFrame for {key}:\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tonducthang = dataframes[\"tuyen_sinh_ton_duc_thang\"]\n",
    "df_phenikaa = dataframes[\"tuyen_sinh_phenikaa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text\n",
      "0                             Đại học,Tin tuyển sinh\n",
      "1        Đại học (https://tuyensinh.edu.vn/dai-hoc/)\n",
      "2  Tin tuyển sinh (https://tuyensinh.edu.vn/tin-t...\n",
      "3  Trường ĐH Tôn Đức Thắng chỉ dành 25% chỉ tiêu ...\n",
      "4  Theo phương án tuyển sinh dự kiến, năm 2022 Tr...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79 entries, 0 to 78\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    79 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 764.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_tonducthang.head())  # Xem 5 dòng đầu tiên\n",
    "print(df_phenikaa.info())       # Xem thông tin tổng quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text\n",
      "0                              Đại họcTin tuyển sinh\n",
      "1                Đại học httpstuyensinh.edu.vndaihoc\n",
      "2   Tin tuyển sinh httpstuyensinh.edu.vntintuyensinh\n",
      "3  Trường Đại học Phenikaa công bố 5 phương thức ...\n",
      "4  Trường Đại học Phenikaa công bố thông tin tuyể...                                                 Text\n",
      "0                              Đại họcTin tuyển sinh\n",
      "1                Đại học httpstuyensinh.edu.vndaihoc\n",
      "2   Tin tuyển sinh httpstuyensinh.edu.vntintuyensinh\n",
      "3  Trường ĐH Tôn Đức Thắng chỉ dành 25 chỉ tiêu x...\n",
      "4  Theo phương án tuyển sinh dự kiến năm 2022 Trư...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                Text\n",
       " 0                             Đại học,Tin tuyển sinh\n",
       " 1        Đại học (https://tuyensinh.edu.vn/dai-hoc/)\n",
       " 2  Tin tuyển sinh (https://tuyensinh.edu.vn/tin-t...\n",
       " 3  Trường Đại học Phenikaa công bố 5 phương thức ...\n",
       " 4  Trường Đại học Phenikaa công bố thông tin tuyể...,\n",
       "                                                 Text\n",
       " 0                             Đại học,Tin tuyển sinh\n",
       " 1        Đại học (https://tuyensinh.edu.vn/dai-hoc/)\n",
       " 2  Tin tuyển sinh (https://tuyensinh.edu.vn/tin-t...\n",
       " 3  Trường ĐH Tôn Đức Thắng chỉ dành 25% chỉ tiêu ...\n",
       " 4  Theo phương án tuyển sinh dự kiến, năm 2022 Tr...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Xóa dấu câu (trừ . ! ?), giữ chữ thường\"\"\"\n",
    "    text = re.sub(r\"[^\\w\\s.!?]\", \"\", text)  # Giữ lại dấu chấm, chấm than, chấm hỏi\n",
    "    return text.strip()\n",
    "\n",
    "# Tạo bản sao DataFrame để làm sạch dữ liệu\n",
    "df_phenikaa_cleaned = df_phenikaa.copy()\n",
    "df_tonducthang_cleaned = df_tonducthang.copy()\n",
    "\n",
    "df_phenikaa_cleaned[\"Text\"] = df_phenikaa_cleaned[\"Text\"].apply(clean_text)\n",
    "df_tonducthang_cleaned[\"Text\"] = df_tonducthang_cleaned[\"Text\"].apply(clean_text)\n",
    "\n",
    "# Kiểm tra dữ liệu sau khi làm sạch\n",
    "print(df_phenikaa_cleaned.head(), df_tonducthang_cleaned.head())\n",
    "\n",
    "# Kiểm tra dữ liệu sau làm sạch\n",
    "df_phenikaa.head(), df_tonducthang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x201a2bc6490>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Vietnamese NLP model\n",
    "nlp = spacy.blank(\"vi\")\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Total Words': 816, 'Total Sentences': 153, 'Total Paragraphs': 79},\n",
       " {'Total Words': 285, 'Total Sentences': 57, 'Total Paragraphs': 27})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_sentences(text):\n",
    "    \"\"\"Chia văn bản thành câu dựa trên dấu câu bằng spaCy\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "def count_words(text):\n",
    "    \"\"\"Đếm số từ bằng spaCy\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return len([token for token in doc if token.is_alpha])\n",
    "\n",
    "def count_stats(texts):\n",
    "    \"\"\"Đếm tổng số từ, câu và đoạn văn \"\"\"\n",
    "    total_words = sum(count_words(text) for text in texts)\n",
    "    total_sentences = sum(len(split_sentences(text)) for text in texts)\n",
    "    total_paragraphs = sum(len(text.strip().split(\"\\n\")) for text in texts)\n",
    "\n",
    "    return {\n",
    "        \"Total Words\": total_words,\n",
    "        \"Total Sentences\": total_sentences,\n",
    "        \"Total Paragraphs\": total_paragraphs\n",
    "    }\n",
    "\n",
    "# Thống kê cho từng tài liệu\n",
    "stats_phenikaa = count_stats(df_phenikaa_cleaned[\"Text\"])\n",
    "stats_tonducthang = count_stats(df_tonducthang_cleaned[\"Text\"])\n",
    "\n",
    "stats_phenikaa, stats_tonducthang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('tuyển', 62),\n",
       "  ('học', 61),\n",
       "  ('xét', 48),\n",
       "  ('sinh', 40),\n",
       "  ('các', 28),\n",
       "  ('có', 23),\n",
       "  ('điểm', 23),\n",
       "  ('với', 22),\n",
       "  ('từ', 21),\n",
       "  ('Trường', 20)],\n",
       " [('tuyển', 21),\n",
       "  ('học', 19),\n",
       "  ('xét', 18),\n",
       "  ('chỉ', 16),\n",
       "  ('sinh', 14),\n",
       "  ('ĐH', 13),\n",
       "  ('trình', 12),\n",
       "  ('THPT', 11),\n",
       "  ('chương', 11),\n",
       "  ('kết', 11)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_word_frequency(texts):\n",
    "    \"\"\"Tạo danh sách từ vựng ban đầu và tính tần suất\"\"\"\n",
    "    vocab = Counter()\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        vocab.update(words)\n",
    "    return vocab\n",
    "\n",
    "# Tính từ vựng ban đầu\n",
    "vocab_phenikaa = compute_word_frequency(df_phenikaa_cleaned[\"Text\"])\n",
    "vocab_tonducthang = compute_word_frequency(df_tonducthang_cleaned[\"Text\"])\n",
    "\n",
    "# Hiển thị 10 từ phổ biến nhất\n",
    "vocab_phenikaa.most_common(10), vocab_tonducthang.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('tuyển', 62),\n",
       "  ('học', 61),\n",
       "  ('xét', 48),\n",
       "  ('sinh', 40),\n",
       "  ('Trường', 20),\n",
       "  ('hợp', 20),\n",
       "  ('Đại', 18),\n",
       "  ('thí', 17),\n",
       "  ('môn', 15),\n",
       "  ('trở', 15)],\n",
       " [('tuyển', 21),\n",
       "  ('học', 19),\n",
       "  ('xét', 18),\n",
       "  ('sinh', 14),\n",
       "  ('ĐH', 13),\n",
       "  ('trình', 12),\n",
       "  ('THPT', 11),\n",
       "  ('chương', 11),\n",
       "  ('kết', 11),\n",
       "  ('Trường', 10)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS_FILE = \"vietnamese-stopwords.txt\"\n",
    "VIETNAMESE_STOPWORDS = set()\n",
    "\n",
    "if os.path.exists(STOPWORDS_FILE):\n",
    "    with open(STOPWORDS_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "        VIETNAMESE_STOPWORDS = set(file.read().strip().split(\"\\n\"))\n",
    "\n",
    "def remove_stopwords(vocab):\n",
    "    \"\"\"Loại bỏ stopwords khỏi từ vựng\"\"\"\n",
    "    return {word: freq for word, freq in vocab.items() if word not in VIETNAMESE_STOPWORDS}\n",
    "\n",
    "# Tạo từ vựng mới sau khi loại bỏ stopwords\n",
    "vocab_v2_phenikaa = remove_stopwords(vocab_phenikaa)\n",
    "vocab_v2_tonducthang = remove_stopwords(vocab_tonducthang)\n",
    "\n",
    "# Hiển thị 10 từ phổ biến nhất sau khi loại bỏ stopwords\n",
    "sorted(vocab_v2_phenikaa.items(), key=lambda x: x[1], reverse=True)[:10], sorted(vocab_v2_tonducthang.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1816, 1737, 1662, 605, 578, 554)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_ngrams(texts):\n",
    "    \"\"\"Trích xuất unigrams, bigrams và trigrams\"\"\"\n",
    "    unigrams, bigrams, trigrams = [], [], []\n",
    "    \n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        unigrams.extend(words)\n",
    "        bigrams.extend(zip(words[:-1], words[1:]))\n",
    "        trigrams.extend(zip(words[:-2], words[1:-1], words[2:]))\n",
    "\n",
    "    return unigrams, bigrams, trigrams\n",
    "\n",
    "# Trích xuất n-grams\n",
    "unigrams_p, bigrams_p, trigrams_p = extract_ngrams(df_phenikaa_cleaned[\"Text\"])\n",
    "unigrams_t, bigrams_t, trigrams_t = extract_ngrams(df_tonducthang_cleaned[\"Text\"])\n",
    "\n",
    "# Hiển thị kết quả\n",
    "len(unigrams_p), len(bigrams_p), len(trigrams_p), len(unigrams_t), len(bigrams_t), len(trigrams_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phenikaa: [['Đại học'], ['Tin tuyển sinh'], ['Điểm chuẩn Đại Học Giáo Dục – Đại học Quốc Gia Hà Nội 2021'], ['ĐH Công nghiệp Hà Nội thêm 3 phương thức xét tuyển mới']]\n",
      "Ton Duc Thang: [['Đại học'], ['Tin tuyển sinh'], ['tại đây'], ['Tuyển sinh 2022: Nhóm ngành ‘nóng’ có nhiều biến động'], ['Năm 2022, ĐH Quốc gia TP.HCM tổ chức 2 đợt thi đánh giá năng lực vào tháng 3 và 5']]\n"
     ]
    }
   ],
   "source": [
    "def extract_anchor_texts(texts):\n",
    "    \"\"\"Trích xuất anchor text từ danh sách văn bản có dạng text (link)\"\"\"\n",
    "    anchor_texts = []\n",
    "    \n",
    "    # Regex tìm text có dạng \"text (URL)\"\n",
    "    pattern = r\"(\\S.*?)(?:\\s*)\\((https?://[^\\s)]+)\\)\"\n",
    "\n",
    "    # Chuyển đổi pandas.Series thành danh sách chuỗi\n",
    "    if isinstance(texts, pd.Series):\n",
    "        texts = texts.dropna().astype(str).tolist()\n",
    "\n",
    "    # Duyệt từng chuỗi trong danh sách\n",
    "    for text in texts:\n",
    "        matches = re.findall(pattern, text)\n",
    "        anchor_texts.extend([match[0].strip() for match in matches])\n",
    "\n",
    "    return anchor_texts\n",
    "\n",
    "df_phenikaa_anchor = df_phenikaa.copy()\n",
    "df_tonducthang_anchor = df_tonducthang.copy()\n",
    "\n",
    "df_phenikaa_anchor[\"Text\"] = df_phenikaa_anchor[\"Text\"].apply(lambda x: extract_anchor_texts([x]) if pd.notna(x) else [])\n",
    "df_tonducthang_anchor[\"Text\"] = df_tonducthang_anchor[\"Text\"].apply(lambda x: extract_anchor_texts([x]) if pd.notna(x) else [])\n",
    "\n",
    "df_phenikaa_anchor = [x for x in df_phenikaa_anchor[\"Text\"].tolist() if x]  \n",
    "df_tonducthang_anchor = [x for x in df_tonducthang_anchor[\"Text\"].tolist() if x] \n",
    "\n",
    "print(\"Phenikaa:\", df_phenikaa_anchor)\n",
    "print(\"Ton Duc Thang:\", df_tonducthang_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'vi_core_news_md'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load mô hình NER tiếng Việt (chọn một trong hai)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m nlp2 \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvi_core_news_md\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# hoặc \"vi_core_news_md\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mextract_named_entities\u001b[39m(texts):\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Thực hiện Named Entity Recognition (NER)\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\Data Science\\.venv\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Data Science\\.venv\\Lib\\site-packages\\spacy\\util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'vi_core_news_md'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load mô hình NER tiếng Việt (chọn một trong hai)\n",
    "nlp2 = spacy.load(\"vi_core_news_md\")  # hoặc \"vi_core_news_md\"\n",
    "\n",
    "def extract_named_entities(texts):\n",
    "    \"\"\"Thực hiện Named Entity Recognition (NER)\"\"\"\n",
    "    entities = []\n",
    "    for text in texts.dropna():  # Bỏ các giá trị NaN trước khi xử lý\n",
    "        doc = nlp2(text)\n",
    "        for ent in doc.ents:\n",
    "            entities.append((ent.text, ent.label_))\n",
    "    return entities\n",
    "\n",
    "# Thực hiện NER\n",
    "ner_phenikaa = extract_named_entities(df_phenikaa[\"Text\"])\n",
    "ner_tonducthang = extract_named_entities(df_tonducthang[\"Text\"])\n",
    "\n",
    "# In 10 kết quả đầu tiên\n",
    "print(\"Phenikaa NER:\", ner_phenikaa[:10])\n",
    "print(\"Ton Duc Thang NER:\", ner_tonducthang[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
