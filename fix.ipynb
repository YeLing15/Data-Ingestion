{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save_stats(url, div_id=None, div_class=None, section_class=None):\n",
    "    driver = webdriver.Chrome()\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        \n",
    "        if div_id:\n",
    "            wait.until(EC.presence_of_element_located((By.ID, div_id)))\n",
    "        elif div_class:\n",
    "            wait.until(EC.presence_of_element_located((By.CLASS_NAME, div_class)))\n",
    "        elif section_class:\n",
    "            wait.until(EC.presence_of_element_located((By.CLASS_NAME, section_class)))\n",
    "        \n",
    "        page_source = driver.page_source\n",
    "        soup = bs(page_source, 'html.parser')\n",
    "\n",
    "        target_element = None\n",
    "        if div_id:\n",
    "            target_element = soup.find('div', {'id': div_id})\n",
    "        elif div_class:\n",
    "            target_element = soup.find('div', {'class': div_class})\n",
    "        elif section_class:\n",
    "            target_element = soup.find('section', {'class': section_class})\n",
    "        else:\n",
    "            target_element = soup.body  # Nếu không có thông số, lấy toàn bộ trang\n",
    "\n",
    "        if not target_element:\n",
    "            print(\"Error: Element with specified identifier not found.\")\n",
    "            return None\n",
    "\n",
    "        content = []\n",
    "        for elem in target_element.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'a']):\n",
    "            text = elem.get_text(strip=True)\n",
    "            if elem.name == 'a' and elem.has_attr('href'):\n",
    "                text += f\" ({elem['href']})\"\n",
    "            if text:\n",
    "                content.append([text])\n",
    "\n",
    "        df = pd.DataFrame(content, columns=[\"Text\"])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_multiple_stats(urls):\n",
    "    dataframes = {}\n",
    "    for key, info in urls.items():\n",
    "        df = fetch_and_save_stats(info[\"url\"], div_id=info.get(\"div_id\"), div_class=info.get(\"div_class\"), section_class=info.get(\"section_class\"))\n",
    "        if df is not None:\n",
    "            dataframes[key] = df\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    \"tuyen_sinh_ton_duc_thang\": {\n",
    "        \"url\": \"https://tuyensinh.edu.vn/dai-hoc/truong-dh-ton-duc-thang-chi-danh-25-chi-tieu-xet-diem-thi-tot-nghiep-thpt/\",\n",
    "        \"div_id\": \"content\",\n",
    "        \"div_class\": \"entry-content single-page\",\n",
    "    },\n",
    "    \"tuyen_sinh_phenikaa\": {\n",
    "        \"url\": \"https://tuyensinh.edu.vn/tin-tuyen-sinh/truong-dai-hoc-phenikaa-cong-bo-5-phuong-thuc-tuyen-sinh-dai-hoc-nam-2022/\",\n",
    "        \"div_id\": \"content\",\n",
    "        \"div_class\": \"entry-content single-page\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error sending stats to Plausible: error sending request for url (https://plausible.io/api/event)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame for tuyen_sinh_ton_duc_thang:\n",
      "                                                 Text\n",
      "0                              Đại học,Tin tuyển sinh\n",
      "1         Đại học (https://tuyensinh.edu.vn/dai-hoc/)\n",
      "2   Tin tuyển sinh (https://tuyensinh.edu.vn/tin-t...\n",
      "3   Trường ĐH Tôn Đức Thắng chỉ dành 25% chỉ tiêu ...\n",
      "4   Theo phương án tuyển sinh dự kiến, năm 2022 Tr...\n",
      "5   Hôm nay 19.1, Trường ĐH Tôn Đức Thắng công bố ...\n",
      "6   Trường ĐH Tôn Đức Thắng dự kiến tuyển 6.500 ch...\n",
      "7   Trường dự kiến tuyển theo 5 phương thức, trong...\n",
      "8   Phương thức 1là xét tuyển theo kết quả quá trì...\n",
      "9   Trong đó, đợt 1 xét tuyển theo kết quả học tập...\n",
      "10  Đợt 2 xét tuyển theo kết quả học tập 6 học kỳ ...\n",
      "11  Đợt 3 xét tuyển theo kết quả học tập 6 học kỳ ...\n",
      "12  Phương thức 2là xét tuyển theo kết quả thi tốt...\n",
      "13  Phương thức 3là ưu tiên xét tuyển theo quy địn...\n",
      "14  Trong đó, đối tượng 1 là thí sinh thuộc các tr...\n",
      "15  Đối tượng 2, 3, 4, 5 xét tuyển vào chương trìn...\n",
      "16  Phương thức 4là xét tuyển thẳng, ưu tiên xét t...\n",
      "17  Phương thức 5là xét tuyển theo kết quả bài thi...\n",
      "18  Thông tin ngành đào tạo, tổ hợp môn xét tuyển ...\n",
      "19  tại đây (https://tuyensinh.edu.vn/wp-content/u...\n",
      "20  Như vậy, so với năm 2021 Trường ĐH Tôn Đức Thắ...\n",
      "21   (whatsapp://send?text=Tr%C6%B0%E1%BB%9Dng%20%...\n",
      "22   (//www.facebook.com/sharer.php?u=https://tuye...\n",
      "23   (//twitter.com/share?url=https://tuyensinh.ed...\n",
      "24   (//tumblr.com/widgets/share/tool?canonicalUrl...\n",
      "25  Tuyển sinh 2022: Nhóm ngành ‘nóng’ có nhiều bi...\n",
      "26  Năm 2022, ĐH Quốc gia TP.HCM tổ chức 2 đợt thi...\n",
      "\n",
      "DataFrame for tuyen_sinh_phenikaa:\n",
      "                                                 Text\n",
      "0                              Đại học,Tin tuyển sinh\n",
      "1         Đại học (https://tuyensinh.edu.vn/dai-hoc/)\n",
      "2   Tin tuyển sinh (https://tuyensinh.edu.vn/tin-t...\n",
      "3   Trường Đại học Phenikaa công bố 5 phương thức ...\n",
      "4   Trường Đại học Phenikaa công bố thông tin tuyể...\n",
      "..                                                ...\n",
      "74   (//www.facebook.com/sharer.php?u=https://tuye...\n",
      "75   (//twitter.com/share?url=https://tuyensinh.ed...\n",
      "76   (//tumblr.com/widgets/share/tool?canonicalUrl...\n",
      "77  Điểm chuẩn Đại Học Giáo Dục – Đại học Quốc Gia...\n",
      "78  ĐH Công nghiệp Hà Nội thêm 3 phương thức xét t...\n",
      "\n",
      "[79 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "dataframes = fetch_multiple_stats(urls)\n",
    "\n",
    "for key, df in dataframes.items():\n",
    "    print(f\"\\nDataFrame for {key}:\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tonducthang = dataframes[\"tuyen_sinh_ton_duc_thang\"]\n",
    "df_phenikaa = dataframes[\"tuyen_sinh_phenikaa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text\n",
      "0                             Đại học,Tin tuyển sinh\n",
      "1        Đại học (https://tuyensinh.edu.vn/dai-hoc/)\n",
      "2  Tin tuyển sinh (https://tuyensinh.edu.vn/tin-t...\n",
      "3  Trường ĐH Tôn Đức Thắng chỉ dành 25% chỉ tiêu ...\n",
      "4  Theo phương án tuyển sinh dự kiến, năm 2022 Tr...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79 entries, 0 to 78\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    79 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 764.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_tonducthang.head())  # Xem 5 dòng đầu tiên\n",
    "print(df_phenikaa.info())       # Xem thông tin tổng quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from spacy.lang.vi import Vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text\n",
      "0                              Đại họcTin tuyển sinh\n",
      "1                Đại học httpstuyensinh.edu.vndaihoc\n",
      "2   Tin tuyển sinh httpstuyensinh.edu.vntintuyensinh\n",
      "3  Trường Đại học Phenikaa công bố 5 phương thức ...\n",
      "4  Trường Đại học Phenikaa công bố thông tin tuyể...                                                 Text\n",
      "0                              Đại họcTin tuyển sinh\n",
      "1                Đại học httpstuyensinh.edu.vndaihoc\n",
      "2   Tin tuyển sinh httpstuyensinh.edu.vntintuyensinh\n",
      "3  Trường ĐH Tôn Đức Thắng chỉ dành 25 chỉ tiêu x...\n",
      "4  Theo phương án tuyển sinh dự kiến năm 2022 Trư...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                Text\n",
       " 0                             Đại học,Tin tuyển sinh\n",
       " 1        Đại học (https://tuyensinh.edu.vn/dai-hoc/)\n",
       " 2  Tin tuyển sinh (https://tuyensinh.edu.vn/tin-t...\n",
       " 3  Trường Đại học Phenikaa công bố 5 phương thức ...\n",
       " 4  Trường Đại học Phenikaa công bố thông tin tuyể...,\n",
       "                                                 Text\n",
       " 0                             Đại học,Tin tuyển sinh\n",
       " 1        Đại học (https://tuyensinh.edu.vn/dai-hoc/)\n",
       " 2  Tin tuyển sinh (https://tuyensinh.edu.vn/tin-t...\n",
       " 3  Trường ĐH Tôn Đức Thắng chỉ dành 25% chỉ tiêu ...\n",
       " 4  Theo phương án tuyển sinh dự kiến, năm 2022 Tr...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Xóa dấu câu (trừ . ! ?), giữ chữ thường\"\"\"\n",
    "    text = re.sub(r\"[^\\w\\s.!?]\", \"\", text)  # Giữ lại dấu chấm, chấm than, chấm hỏi\n",
    "    return text.strip()\n",
    "\n",
    "# Tạo bản sao DataFrame để làm sạch dữ liệu\n",
    "df_phenikaa_cleaned = df_phenikaa.copy()\n",
    "df_tonducthang_cleaned = df_tonducthang.copy()\n",
    "\n",
    "df_phenikaa_cleaned[\"Text\"] = df_phenikaa_cleaned[\"Text\"].apply(clean_text)\n",
    "df_tonducthang_cleaned[\"Text\"] = df_tonducthang_cleaned[\"Text\"].apply(clean_text)\n",
    "\n",
    "# Kiểm tra dữ liệu sau khi làm sạch\n",
    "print(df_phenikaa_cleaned.head(), df_tonducthang_cleaned.head())\n",
    "\n",
    "# Kiểm tra dữ liệu sau làm sạch\n",
    "df_phenikaa.head(), df_tonducthang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x2443fb79490>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Vietnamese NLP model\n",
    "nlp = Vietnamese()\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Total Words': 816, 'Total Sentences': 153, 'Total Paragraphs': 79},\n",
       " {'Total Words': 285, 'Total Sentences': 57, 'Total Paragraphs': 27})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_sentences(text):\n",
    "    \"\"\"Chia văn bản thành câu dựa trên dấu câu bằng spaCy\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "def count_words(text):\n",
    "    \"\"\"Đếm số từ bằng spaCy\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return len([token for token in doc if token.is_alpha])\n",
    "\n",
    "def count_stats(texts):\n",
    "    \"\"\"Đếm tổng số từ, câu và đoạn văn \"\"\"\n",
    "    total_words = sum(count_words(text) for text in texts)\n",
    "    total_sentences = sum(len(split_sentences(text)) for text in texts)\n",
    "    total_paragraphs = sum(len(text.strip().split(\"\\n\")) for text in texts)\n",
    "\n",
    "    return {\n",
    "        \"Total Words\": total_words,\n",
    "        \"Total Sentences\": total_sentences,\n",
    "        \"Total Paragraphs\": total_paragraphs\n",
    "    }\n",
    "\n",
    "# Thống kê cho từng tài liệu\n",
    "stats_phenikaa = count_stats(df_phenikaa_cleaned[\"Text\"])\n",
    "stats_tonducthang = count_stats(df_tonducthang_cleaned[\"Text\"])\n",
    "\n",
    "stats_phenikaa, stats_tonducthang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('tuyển', 62),\n",
       "  ('học', 61),\n",
       "  ('xét', 48),\n",
       "  ('sinh', 40),\n",
       "  ('các', 28),\n",
       "  ('có', 23),\n",
       "  ('điểm', 23),\n",
       "  ('với', 22),\n",
       "  ('từ', 21),\n",
       "  ('Trường', 20)],\n",
       " [('tuyển', 21),\n",
       "  ('học', 19),\n",
       "  ('xét', 18),\n",
       "  ('chỉ', 16),\n",
       "  ('sinh', 14),\n",
       "  ('ĐH', 13),\n",
       "  ('trình', 12),\n",
       "  ('THPT', 11),\n",
       "  ('chương', 11),\n",
       "  ('kết', 11)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_word_frequency(texts):\n",
    "    \"\"\"Tạo danh sách từ vựng ban đầu và tính tần suất\"\"\"\n",
    "    vocab = Counter()\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        vocab.update(words)\n",
    "    return vocab\n",
    "\n",
    "# Tính từ vựng ban đầu\n",
    "vocab_phenikaa = compute_word_frequency(df_phenikaa_cleaned[\"Text\"])\n",
    "vocab_tonducthang = compute_word_frequency(df_tonducthang_cleaned[\"Text\"])\n",
    "\n",
    "# Hiển thị 10 từ phổ biến nhất\n",
    "vocab_phenikaa.most_common(10), vocab_tonducthang.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('tuyển', 62),\n",
       "  ('học', 61),\n",
       "  ('xét', 48),\n",
       "  ('sinh', 40),\n",
       "  ('Trường', 20),\n",
       "  ('hợp', 20),\n",
       "  ('Đại', 18),\n",
       "  ('thí', 17),\n",
       "  ('môn', 15),\n",
       "  ('trở', 15)],\n",
       " [('tuyển', 21),\n",
       "  ('học', 19),\n",
       "  ('xét', 18),\n",
       "  ('sinh', 14),\n",
       "  ('ĐH', 13),\n",
       "  ('trình', 12),\n",
       "  ('THPT', 11),\n",
       "  ('chương', 11),\n",
       "  ('kết', 11),\n",
       "  ('Trường', 10)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS_FILE = \"vietnamese-stopwords.txt\"\n",
    "VIETNAMESE_STOPWORDS = set()\n",
    "\n",
    "if os.path.exists(STOPWORDS_FILE):\n",
    "    with open(STOPWORDS_FILE, \"r\", encoding=\"utf-8\") as file:\n",
    "        VIETNAMESE_STOPWORDS = set(file.read().strip().split(\"\\n\"))\n",
    "\n",
    "def remove_stopwords(vocab):\n",
    "    \"\"\"Loại bỏ stopwords khỏi từ vựng\"\"\"\n",
    "    return {word: freq for word, freq in vocab.items() if word not in VIETNAMESE_STOPWORDS}\n",
    "\n",
    "# Tạo từ vựng mới sau khi loại bỏ stopwords\n",
    "vocab_v2_phenikaa = remove_stopwords(vocab_phenikaa)\n",
    "vocab_v2_tonducthang = remove_stopwords(vocab_tonducthang)\n",
    "\n",
    "# Hiển thị 10 từ phổ biến nhất sau khi loại bỏ stopwords\n",
    "sorted(vocab_v2_phenikaa.items(), key=lambda x: x[1], reverse=True)[:10], sorted(vocab_v2_tonducthang.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1816, 1737, 1662, 605, 578, 554)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_ngrams(texts):\n",
    "    \"\"\"Trích xuất unigrams, bigrams và trigrams\"\"\"\n",
    "    unigrams, bigrams, trigrams = [], [], []\n",
    "    \n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        unigrams.extend(words)\n",
    "        bigrams.extend(zip(words[:-1], words[1:]))\n",
    "        trigrams.extend(zip(words[:-2], words[1:-1], words[2:]))\n",
    "\n",
    "    return unigrams, bigrams, trigrams\n",
    "\n",
    "# Trích xuất n-grams\n",
    "unigrams_p, bigrams_p, trigrams_p = extract_ngrams(df_phenikaa_cleaned[\"Text\"])\n",
    "unigrams_t, bigrams_t, trigrams_t = extract_ngrams(df_tonducthang_cleaned[\"Text\"])\n",
    "\n",
    "# Hiển thị kết quả\n",
    "len(unigrams_p), len(bigrams_p), len(trigrams_p), len(unigrams_t), len(bigrams_t), len(trigrams_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phenikaa: [['Đại học'], ['Tin tuyển sinh'], ['Điểm chuẩn Đại Học Giáo Dục – Đại học Quốc Gia Hà Nội 2021'], ['ĐH Công nghiệp Hà Nội thêm 3 phương thức xét tuyển mới']]\n",
      "Ton Duc Thang: [['Đại học'], ['Tin tuyển sinh'], ['tại đây'], ['Tuyển sinh 2022: Nhóm ngành ‘nóng’ có nhiều biến động'], ['Năm 2022, ĐH Quốc gia TP.HCM tổ chức 2 đợt thi đánh giá năng lực vào tháng 3 và 5']]\n"
     ]
    }
   ],
   "source": [
    "def extract_anchor_texts(texts):\n",
    "    \"\"\"Trích xuất anchor text từ danh sách văn bản có dạng text (link)\"\"\"\n",
    "    anchor_texts = []\n",
    "    \n",
    "    # Regex tìm text có dạng \"text (URL)\"\n",
    "    pattern = r\"(\\S.*?)(?:\\s*)\\((https?://[^\\s)]+)\\)\"\n",
    "\n",
    "    # Chuyển đổi pandas.Series thành danh sách chuỗi\n",
    "    if isinstance(texts, pd.Series):\n",
    "        texts = texts.dropna().astype(str).tolist()\n",
    "\n",
    "    # Duyệt từng chuỗi trong danh sách\n",
    "    for text in texts:\n",
    "        matches = re.findall(pattern, text)\n",
    "        anchor_texts.extend([match[0].strip() for match in matches])\n",
    "\n",
    "    return anchor_texts\n",
    "\n",
    "df_phenikaa_anchor = df_phenikaa.copy()\n",
    "df_tonducthang_anchor = df_tonducthang.copy()\n",
    "\n",
    "df_phenikaa_anchor[\"Text\"] = df_phenikaa_anchor[\"Text\"].apply(lambda x: extract_anchor_texts([x]) if pd.notna(x) else [])\n",
    "df_tonducthang_anchor[\"Text\"] = df_tonducthang_anchor[\"Text\"].apply(lambda x: extract_anchor_texts([x]) if pd.notna(x) else [])\n",
    "\n",
    "df_phenikaa_anchor = [x for x in df_phenikaa_anchor[\"Text\"].tolist() if x]  \n",
    "df_tonducthang_anchor = [x for x in df_tonducthang_anchor[\"Text\"].tolist() if x] \n",
    "\n",
    "print(\"Phenikaa:\", df_phenikaa_anchor)\n",
    "print(\"Ton Duc Thang:\", df_tonducthang_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
    "from pyvi import ViTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForTokenClassification requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m MODEL_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnguyenvulebinh/vi-mrc-large\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Pre-trained Vietnamese NER model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL_NAME)\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForTokenClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(MODEL_NAME)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create NER pipeline\u001b[39;00m\n\u001b[0;32m      7\u001b[0m ner_pipeline \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mner\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n",
      "File \u001b[1;32md:\\Data Science\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1736\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1736\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Data Science\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1724\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1722\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m   1723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 1724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nAutoModelForTokenClassification requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained Vietnamese NER model\n",
    "MODEL_NAME = \"nguyenvulebinh/vi-mrc-large\"  # Pre-trained Vietnamese NER model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Create NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phenikaa NER: []\n",
      "Ton Duc Thang NER: []\n"
     ]
    }
   ],
   "source": [
    "def extract_named_entities(texts):\n",
    "    \"\"\"Thực hiện Named Entity Recognition (NER) với BERT và ViTokenizer\"\"\"\n",
    "    entities = []\n",
    "    for text in texts.dropna():\n",
    "        tokenized_text = ViTokenizer.tokenize(text)  # Tokenize Vietnamese text\n",
    "        ner_results = ner_pipeline(tokenized_text)  # Run through BERT NER model\n",
    "        \n",
    "        # Process extracted entities\n",
    "        for entity in ner_results:\n",
    "            entities.append((entity['word'], entity['entity']))\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Thực hiện NER\n",
    "ner_phenikaa = extract_named_entities(df_phenikaa[\"Text\"])\n",
    "ner_tonducthang = extract_named_entities(df_tonducthang[\"Text\"])\n",
    "\n",
    "# In 10 kết quả đầu tiên\n",
    "print(\"Phenikaa NER:\", ner_phenikaa[:10])\n",
    "print(\"Ton Duc Thang NER:\", ner_tonducthang[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
