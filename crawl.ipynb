{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save_stats(url, filename_prefix, div_id=None, div_class=None, section_class=None):\n",
    "    # Initialize the WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    try:\n",
    "        # Load the webpage\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the div with the specified ID, class, or section class to load\n",
    "        wait = WebDriverWait(driver, 20)\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        if div_id:\n",
    "            wait.until(EC.presence_of_element_located((By.ID, div_id)))\n",
    "        elif div_class:\n",
    "            wait.until(EC.presence_of_element_located((By.CLASS_NAME, div_class)))\n",
    "        elif section_class:\n",
    "            wait.until(EC.presence_of_element_located((By.CLASS_NAME, section_class)))\n",
    "\n",
    "        # Get page source and parse it with BeautifulSoup\n",
    "        page_source = driver.page_source\n",
    "        soup = bs(page_source, 'html.parser')\n",
    "\n",
    "        # Find the target div or section\n",
    "        target_element = None\n",
    "        if div_id:\n",
    "            target_element = soup.find('div', {'id': div_id})\n",
    "        elif div_class:\n",
    "            target_element = soup.find('div', {'class': div_class})\n",
    "        elif section_class:\n",
    "            target_element = soup.find('section', {'class': section_class})\n",
    "\n",
    "        if not target_element:\n",
    "            print(f\"Error: element with {'id' if div_id else 'class' if div_class else 'section class'} '{div_id if div_id else div_class if div_class else section_class}' not found.\")\n",
    "            return\n",
    "\n",
    "        # Extract all relevant content from the target element\n",
    "        content = {}\n",
    "\n",
    "        # Extract headers (h1, h2, h3, etc.) within the target element\n",
    "        headers = target_element.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "        content['headers'] = [header.text.strip() for header in headers if header and header.text]\n",
    "\n",
    "        # Extract paragraphs within the target element\n",
    "        paragraphs = target_element.find_all('p')\n",
    "        content['paragraphs'] = [paragraph.text.strip() for paragraph in paragraphs if paragraph and paragraph.text]\n",
    "\n",
    "        # Find all tables within the target element\n",
    "        tables = target_element.find_all('table')\n",
    "        content['tables'] = []\n",
    "\n",
    "        if tables:\n",
    "            # Iterate through each table and extract data\n",
    "            for table_idx, table in enumerate(tables):\n",
    "                table_data = extract_table_data(table, table_idx)\n",
    "                if table_data:\n",
    "                    content['tables'].append(table_data)\n",
    "\n",
    "        # Extract course information within includeBox class\n",
    "        include_boxes = target_element.find_all('div', class_='includeBox')\n",
    "        content['courses'] = extract_course_data(include_boxes)\n",
    "\n",
    "        # Save data to files\n",
    "        save_data(content, filename_prefix)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "    finally:\n",
    "        # Ensure the WebDriver is closed properly\n",
    "        driver.quit()\n",
    "\n",
    "def extract_table_data(table, table_idx):\n",
    "    \"\"\"Extracts data from a table element.\"\"\"\n",
    "    headers = []\n",
    "    thead = table.find('thead')\n",
    "    if not thead:\n",
    "        print(f\"Error: thead not found in table {table_idx}.\")\n",
    "        return None\n",
    "\n",
    "    # Assuming the first two rows are header rows\n",
    "    first_row = thead.find_all('tr')[0]\n",
    "    second_row = thead.find_all('tr')[1]\n",
    "\n",
    "    # Combine headers\n",
    "    combined_headers = []\n",
    "    first_row_headers = []\n",
    "\n",
    "    for th in first_row.find_all('th'):\n",
    "        colspan = int(th.get('colspan', 1))\n",
    "        label = th.text.strip() if th.text else ''\n",
    "        first_row_headers.extend([label] * colspan)\n",
    "\n",
    "    for idx, th in enumerate(second_row.find_all('th')):\n",
    "        aria_label = th.text.strip() if th.text else ''\n",
    "        broader_category = first_row_headers[idx]\n",
    "        combined_header = f\"{broader_category} - {aria_label}\" if broader_category else aria_label\n",
    "        combined_headers.append(combined_header)\n",
    "\n",
    "    # Flatten headers for CSV\n",
    "    flattened_headers = [header.replace(\" - \", \"-\") for header in combined_headers]\n",
    "\n",
    "    # Extract data from tbody\n",
    "    semester_course = []\n",
    "    tbody = table.find('tbody')\n",
    "    if tbody:\n",
    "        rows = tbody.find_all('tr')\n",
    "        for row in rows:\n",
    "            first_column = row.find('th').text.strip() if row.find('th') else ''\n",
    "            columns = [col.text.strip() for col in row.find_all('td')]\n",
    "            if not columns:\n",
    "                continue\n",
    "\n",
    "            # Create a dictionary for each row\n",
    "            row_data = {flattened_headers[0]: first_column}  # First column (e.g., rank)\n",
    "            for idx, column in enumerate(columns):\n",
    "                row_data[flattened_headers[idx + 1]] = column\n",
    "\n",
    "            semester_course.append(row_data)\n",
    "\n",
    "    return semester_course\n",
    "\n",
    "def extract_course_data(include_boxes):\n",
    "    \"\"\"Extracts course data from includeBox class.\"\"\"\n",
    "    course_data = []\n",
    "\n",
    "    for box in include_boxes:\n",
    "        strong_text = box.find('strong').text.strip() if box.find('strong') else 'N/A'\n",
    "        teacher_text = box.find('em').next_sibling.strip() if box.find('em') and box.find('em').next_sibling else 'N/A'\n",
    "        code_text = box.find(string=lambda text: 'CS-' in text)\n",
    "        code_text = code_text.strip() if code_text else 'N/A'\n",
    "\n",
    "        # Extract all links and titles\n",
    "        links = box.find_all('a')\n",
    "        course_links = [\n",
    "            {'title': link.find('strong').text.strip() if link.find('strong') else 'N/A', 'url': link['href']} \n",
    "            for link in links if link and link.get('href')\n",
    "        ]\n",
    "\n",
    "        # Compile all course data\n",
    "        course_data.append({\n",
    "            'Course Title': strong_text,\n",
    "            'Teacher': teacher_text,\n",
    "            'Code': code_text,\n",
    "            'Links': course_links\n",
    "        })\n",
    "\n",
    "    return course_data\n",
    "\n",
    "def save_data(content, filename_prefix):\n",
    "    \"\"\"Saves the extracted data to text and CSV files.\"\"\"\n",
    "    # Save headers and paragraphs to a text file\n",
    "    txt_filename = f\"{filename_prefix}.txt\"\n",
    "    with open(txt_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Headers:\\n\")\n",
    "        for header in content['headers']:\n",
    "            f.write(f\"{header}\\n\")\n",
    "        f.write(\"\\nParagraphs:\\n\")\n",
    "        for paragraph in content['paragraphs']:\n",
    "            f.write(f\"{paragraph}\\n\")\n",
    "\n",
    "    print(f\"Content saved to {txt_filename}\")\n",
    "\n",
    "    # Save each table's data to CSV files\n",
    "    for idx, table in enumerate(content['tables']):\n",
    "        if table:\n",
    "            df = pd.DataFrame(table)\n",
    "            csv_filename = f\"{filename_prefix}_table_{idx}.csv\"\n",
    "            df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "            print(f\"Table {idx} saved to {csv_filename}\")\n",
    "\n",
    "    # Save course data to a CSV file\n",
    "    if content['courses']:\n",
    "        course_df = pd.DataFrame(content['courses'])\n",
    "        course_csv_filename = f\"{filename_prefix}_courses.csv\"\n",
    "        course_df.to_csv(course_csv_filename, index=False, encoding='utf-8')\n",
    "        print(f\"Course data saved to {course_csv_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    \"ethz_computer_science_bachelor\": {\n",
    "    \"url\": \"https://inf.ethz.ch/studies/bachelor.html\",\n",
    "    \"div_id\": \"contentContainer\",    \n",
    "    },\n",
    "    \"ethz_computer_science_master\": {\n",
    "    \"url\": \"https://inf.ethz.ch/studies/master/master-cs-2020.html\",\n",
    "    \"div_id\": \"contentContainer\",    \n",
    "    },\n",
    "    \"ethz_data_science_master\": {\n",
    "    \"url\": \"https://inf.ethz.ch/studies/master/master-ds.html\",\n",
    "    \"div_id\": \"contentContainer\",    \n",
    "    },\n",
    "    \"ethz_data_management_anh_machine_learning_research\": {\n",
    "    \"url\": \"https://inf.ethz.ch/research/data-management-machine-learning.html\",\n",
    "    \"div_id\": \"contentContainer\",    \n",
    "    },\n",
    "    \"ethz_intelligent_interactive_research\": {\n",
    "    \"url\": \"https://inf.ethz.ch/research/intelligent-interactive-systems-and-physical-computing.html\",\n",
    "    \"div_id\": \"contentContainer\",    \n",
    "    },\n",
    "    \"ethz_visual_computing_research\": {\n",
    "    \"url\": \"https://inf.ethz.ch/research/visual-computing.html\",\n",
    "    \"div_id\": \"contentContainer\",    \n",
    "    },\n",
    "    \"ethz_computer_science_lab\": {\n",
    "    \"url\": \"https://inf.ethz.ch/department/rooms-labs-beamers.html\",\n",
    "    \"div_id\": \"contentContainer\",    \n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    \"usi_computer_science_bachelor\": {\n",
    "    \"url\": \"https://www.usi.ch/en/education/bachelor/informatics/structure-and-contents\",\n",
    "    \"div_id\": None,\n",
    "    \"div_class\": \"page_content\",    \n",
    "    },\n",
    "    \"usi_data_science_bachelor\": {\n",
    "    \"url\": \"https://www.usi.ch/en/education/bachelor/data-science/structure-and-contents\",\n",
    "    \"div_id\": None,\n",
    "    \"div_class\": \"page_content\",    \n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    \"unibas_computer_science_bachelor\": {\n",
    "    \"url\": \"https://www.unibas.ch/en/Studies/Degree-Programs/Degree-Programs.html?study=Computer-Science-BSc\",\n",
    "    \"div_id\": None,\n",
    "    \"section_class\": \"content_block clearfix narrow-article-content\",\n",
    "    \"div_class\": \"content_wides tudysubject\",    \n",
    "    },\n",
    "    \"unibas_computer_science_bachelor_associate\": {\n",
    "    \"url\": \"https://www.unibas.ch/en/Studies/Degree-Programs/Degree-Programs.html?study=Computer-Science-Ausserfakultaeres-Bachelorstudienfach\",\n",
    "    \"div_id\": None,\n",
    "    \"section_class\": \"content_block clearfix narrow-article-content\",\n",
    "    \"div_class\": \"content_wide studysubject\",    \n",
    "    },\n",
    "    \"unibas_computer_science_master\": {\n",
    "    \"url\": \"https://www.unibas.ch/en/Studies/Degree-Programs/Degree-Programs.html?study=Computer-Science-MSc\",\n",
    "    \"div_id\": None,\n",
    "    \"section_class\": \"content_block clearfix narrow-article-content\",\n",
    "    \"div_class\": \"content_wide studysubject\",    \n",
    "    },\n",
    "    \"unibas_computer_science_master_associate\": {\n",
    "    \"url\": \"https://www.unibas.ch/en/Studies/Degree-Programs/Degree-Programs.html?study=Computer-Science-Ausserfakultaeres-Masterstudienfach\",\n",
    "    \"div_id\": None,\n",
    "    \"section_class\": \"content_block clearfix narrow-article-content\",\n",
    "    \"div_class\": \"content_wide studysubject\",    \n",
    "    },\n",
    "    \"unibas_data_science_master\": {\n",
    "    \"url\": \"https://www.unibas.ch/en/Studies/Degree-Programs/Degree-Programs.html?study=Computer-Science-MSc0\",\n",
    "    \"div_id\": None,\n",
    "    \"section_class\": \"content_block clearfix narrow-article-content\",\n",
    "    \"div_class\": \"content_wide studysubject\",    \n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('crawled'):\n",
    "    os.makedirs('crawled')\n",
    "\n",
    "# Fetch data\n",
    "for stat_type, info in urls.items():\n",
    "    fetch_and_save_stats(info['url'], f\"./crawled/data_{stat_type}\", info['div_id'], info['div_class'], info['section_class'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
